{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FaceRecognition.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMYqFX9/a2YH8FWEqnWOmib"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"G7wxCYrWiAay"},"source":["# Face Recognition System"]},{"cell_type":"markdown","metadata":{"id":"OmtGzdKWj6Yt"},"source":["In Face Encoding we find out different measures of the face which are used to distinguish different people. It is done using Deep Metric Learning and it gives same measures for same face and different measures for different faces. We don't know what these measures are but machine knows.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eKacTc4ViD9Y"},"source":["### Installing Face Recognition Library"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OgDxK2HmZhP9","executionInfo":{"status":"ok","timestamp":1618694637575,"user_tz":-300,"elapsed":30438,"user":{"displayName":"MUHAMMAD FAHAD ALAM","photoUrl":"","userId":"13030919680603969645"}},"outputId":"4ba02266-6e04-457c-b6e8-a5adedbbb79d"},"source":["!pip install face_recognition"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting face_recognition\n","  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Collecting face-recognition-models>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n","\u001b[K     |████████████████████████████████| 100.2MB 39kB/s \n","\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=59edf1c757a0a394a336fc035382ed8eaa2d70d4a4d279a5501d6b38dda9d699\n","  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face-recognition\n","Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ulVrdDkoiKwg"},"source":["### Importing Required Modules"]},{"cell_type":"code","metadata":{"id":"65EPAQm7VuFo","executionInfo":{"status":"ok","timestamp":1618695124125,"user_tz":-300,"elapsed":4498,"user":{"displayName":"MUHAMMAD FAHAD ALAM","photoUrl":"","userId":"13030919680603969645"}}},"source":["import PIL.Image\n","import face_recognition\n","import numpy as np\n","import requests\n","from io import BytesIO"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OTmPR-N0bsZV"},"source":["## Images to use for Testing\n","https://images.pexels.com/photos/1037915/pexels-photo-1037915.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940\n","<br>\n","https://images.unsplash.com/photo-1590750093844-bc3ae9e48f9c?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=334&q=80\n","<br>\n","https://images.unsplash.com/photo-1502323703385-c3ea9ace787d?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=334&q=80"]},{"cell_type":"markdown","metadata":{"id":"QIaxy7zhiQ64"},"source":["#### To read image in files path"]},{"cell_type":"markdown","metadata":{"id":"njtEFH_tck2J"},"source":["image = face_recognition.load_image_file('PATH HERE')"]},{"cell_type":"markdown","metadata":{"id":"VLo7WCnLiVnM"},"source":["### Read Image from Image URL"]},{"cell_type":"code","metadata":{"id":"TeP1AZZOcbJA","executionInfo":{"status":"ok","timestamp":1618695126759,"user_tz":-300,"elapsed":2623,"user":{"displayName":"MUHAMMAD FAHAD ALAM","photoUrl":"","userId":"13030919680603969645"}}},"source":["image1 = np.array(PIL.Image.open(BytesIO(requests.get('https://images.pexels.com/photos/1037915/pexels-photo-1037915.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940').content)))\n","image2 = np.array(PIL.Image.open(BytesIO(requests.get('https://images.unsplash.com/photo-1590750093844-bc3ae9e48f9c?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=334&q=80').content)))\n","image3 = np.array(PIL.Image.open(BytesIO(requests.get('https://images.unsplash.com/photo-1502323703385-c3ea9ace787d?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=334&q=80').content)))"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YZ5nhrqLsN9L"},"source":["### Face Encoding"]},{"cell_type":"markdown","metadata":{"id":"48iACmSXsQgT"},"source":["It returns measures from the image which are used for comparison. If the person is same than these measures would be close."]},{"cell_type":"code","metadata":{"id":"jCHlgiKnjTdf","executionInfo":{"status":"ok","timestamp":1618695192508,"user_tz":-300,"elapsed":2473,"user":{"displayName":"MUHAMMAD FAHAD ALAM","photoUrl":"","userId":"13030919680603969645"}}},"source":["face_encoding1 = face_recognition.face_encodings(image1)[0]\n","face_encoding2 = face_recognition.face_encodings(image2)[0]\n","face_encoding3 = face_recognition.face_encodings(image3)[0]"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v2wt1dWrseHj"},"source":["### Known Faces Array"]},{"cell_type":"code","metadata":{"id":"IZ2nQx16r2Ui","executionInfo":{"status":"ok","timestamp":1618695917217,"user_tz":-300,"elapsed":1121,"user":{"displayName":"MUHAMMAD FAHAD ALAM","photoUrl":"","userId":"13030919680603969645"}}},"source":["known_face_encoding = [\n","                       face_encoding1,\n","                       face_encoding2,\n","                       face_encoding3\n","]"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"buLeZZjwxYYE"},"source":["## Recognizing"]},{"cell_type":"markdown","metadata":{"id":"NwTfSp2xxcio"},"source":["### Unknown Face"]},{"cell_type":"code","metadata":{"id":"1P0bljCCsF1f","executionInfo":{"status":"ok","timestamp":1618695572441,"user_tz":-300,"elapsed":1611,"user":{"displayName":"MUHAMMAD FAHAD ALAM","photoUrl":"","userId":"13030919680603969645"}}},"source":["unknown = np.array(PIL.Image.open(BytesIO(requests.get('https://images.unsplash.com/photo-1502323703385-c3ea9ace787d?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=334&q=80').content)))"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kPmM3w_RxoeJ"},"source":["### Encoding"]},{"cell_type":"markdown","metadata":{"id":"kJraKugu1yIl"},"source":["Simple encoding may miss small faces."]},{"cell_type":"code","metadata":{"id":"aQbJd3F1xkVm","executionInfo":{"status":"ok","timestamp":1618696701336,"user_tz":-300,"elapsed":1552,"user":{"displayName":"MUHAMMAD FAHAD ALAM","photoUrl":"","userId":"13030919680603969645"}}},"source":["unknown_encodings = face_recognition.face_encodings(unknown)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IYBp4wUU0GHR"},"source":["## Tuning Simple Encoding to improve accuracy"]},{"cell_type":"markdown","metadata":{"id":"O4FWtGFc02WC"},"source":["If the image is low resolution and the face is too small the face_encoding method would not be able to give any output as the face would not be detected. For solving this problem we can detect faces first and than encode them. Not directly encode the image. \n","\n","Now we have 2 steps:\n","\n","*   Face Detection \n","*   Face Encoding on detected faces.\n","\n","We can use upsample to increase the size of image to detect the face in the image. In this way small images can also be detected and matched.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"jdPSADeT0Oaq","executionInfo":{"status":"ok","timestamp":1618696702810,"user_tz":-300,"elapsed":1198,"user":{"displayName":"MUHAMMAD FAHAD ALAM","photoUrl":"","userId":"13030919680603969645"}}},"source":["face_locations = face_recognition.face_locations(unknown, number_of_times_to_upsample = 2)\n","\n","unknown_encodings = face_recognition.face_encodings(unknown, known_face_locations = face_locations )"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PUbCL5p2zgrF"},"source":["#Output"]},{"cell_type":"markdown","metadata":{"id":"Df1nUgeizBSt"},"source":["Compare every face in the unknown image to check whether it is same face as the known images. if yes than the encoding will be same and the name will be displayed else the image face does not match with any known faces"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i_p1KajBxzoe","executionInfo":{"status":"ok","timestamp":1618696704563,"user_tz":-300,"elapsed":567,"user":{"displayName":"MUHAMMAD FAHAD ALAM","photoUrl":"","userId":"13030919680603969645"}},"outputId":"07a4dca2-fc0b-4a09-c003-f90cefd95704"},"source":["for unknown_encoding in unknown_encodings:\n","\n","  results = face_recognition.compare_faces(known_face_encoding, unknown_encoding)\n","\n","  name = \"Unknown\"\n","\n","  if results[0]:\n","    \n","    name = \"Person 1\"\n","  elif results[1]:\n","    name = \"Person 2\"\n","  elif results[2]:\n","    name = \"Person 3\"\n","\n","  print(f\"The person in the image is {name}\")\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["The person in the image is Person 3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2EGR2-hXyynH"},"source":[""],"execution_count":null,"outputs":[]}]}